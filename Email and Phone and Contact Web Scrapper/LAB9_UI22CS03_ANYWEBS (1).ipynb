{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Let's Make a Webscraping tool using python that extract phone number and email from any webpage"
      ],
      "metadata": {
        "id": "99d342_b2Fnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKbRwNXsmMiy",
        "outputId": "bf283669-0d40-4e07-86fe-42e17e7995fa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83OfO00MmVfh",
        "outputId": "87816cdd-687f-4ec9-ad1b-8dd4e1b1d906"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the requried library\n",
        "#Request library in Python is used to make HTTP requests, and it serves a wide range of purposes\n",
        "\n",
        "import requests\n",
        "#Beautiful Soup is a popular Python library used in web scraping and parsing HTML and XML documents\n",
        "from bs4 import BeautifulSoup\n",
        "# re module in Python, short for \"regular expressions,\" is a powerful tool for working with text and pattern matching.\n",
        "import re\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "B1RzqQvt0k-_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's take input of website to extract contact details\n",
        "url = input(\"Enter the Webpage URL: \")\n",
        "urlrequest=requests.get(url)"
      ],
      "metadata": {
        "id": "-A1OoWTDzMxz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "044ae5d1-2b7c-4266-968d-7e442a2708e6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the Webpage URL: http://www.iiitsurat.ac.in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Soup is used to parse and navigate the HTML content of a webpage\n",
        "soup = BeautifulSoup(urlrequest.text, 'html.parser')"
      ],
      "metadata": {
        "id": "OO5UTkOEzjS9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Below is used to extract plain text content from the BeautifulSoup object soup\n",
        "text = soup.get_text()"
      ],
      "metadata": {
        "id": "doJw5dcM0p5u"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#It will print all html webpage texts\n",
        "print(text)"
      ],
      "metadata": {
        "id": "xL3_v0KE0sGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6df92cad-74d6-4465-9102-43977d83c92e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "IIIT Surat :: Home\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Home\n",
            "\n",
            "About IIIT Surat\n",
            "\n",
            "About IIIT Surat\n",
            "Vision & Mission\n",
            "Director's Desk\n",
            "Board of Governors\n",
            "Finance Committee\n",
            "Senate\n",
            "Administration\n",
            "\n",
            "Faculty\n",
            "\n",
            "\n",
            "MOU\n",
            "\n",
            "\n",
            "Academics\n",
            "\n",
            "B.Tech 2018-2022\n",
            "B.Tech 2022-23 onwards\n",
            "Academic Calendar\n",
            "Holiday List\n",
            "B.Tech Academic Rules\n",
            "Ph.D Academic Rules\n",
            "Ph.D Fee Structure\n",
            "\n",
            "\n",
            "Admission\n",
            "\n",
            "Admission 2023\n",
            "\n",
            "\n",
            "\n",
            "Results\n",
            "RTI\n",
            "T & P\n",
            "Career\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Links for Students\n",
            "\n",
            "IIIT-Surat Moodle\n",
            "IIIT-Surat Coursera\n",
            "IIIT-Surat Github\n",
            "IIIT-MATLAB\n",
            "NEWSLETTERS\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Events\n",
            "\n",
            "2nd Convocation Ceremony 19-08-2023\n",
            "International Yoga Day 21st June 2023\n",
            "World Environment Day 2023\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Notification\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Useful Links\n",
            "\n",
            "National Overseas Scholarship Scheme for the 2022-23\n",
            "Loksabha Research Fellowships\n",
            "National Scholarship Portal\n",
            "Uttar Pradesh Government - Scholarship System\n",
            "\n",
            "\n",
            "Read More\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " MoE Initiatives\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Follow us on Facebook\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Follow us on Twitter\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Gallery\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Follow us on Youtube\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "About Us\n",
            "\n",
            "About IIIT Surat\n",
            "Vision & Mission\n",
            "Director's Desk\n",
            "Board of Governors\n",
            "Administration\n",
            "\n",
            "Contact Us\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Where we are?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Contact\n",
            "\n",
            "Indian Institute of Information Technology, Surat\n",
            "Kholvad Campus\n",
            "Kamrej, Surat  - 394190\n",
            "Gujarat\n",
            "Phone : 02621-298060\n",
            "Email : office@iiitsurat.ac.in\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Our Partners\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GNFC\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Gujarat Informatics Limited\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Gujarat Gas Limited\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SBI Collect\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Â© Copyrights 2019. All Rights Reserved Credo Infotech\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's find all the occurance of String \"Phone\" in webpage text\n",
        "phone= soup.find_all(text=re.compile(r'Phone', re.I))\n",
        "df_phone=pd.DataFrame(phone)\n",
        "print(df_phone)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FUWKMJ807sI",
        "outputId": "ae0d75d7-cd79-49c2-c761-eddc2440aef5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      0\n",
            "0  Phone : 02621-298060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-e8906c7e3018>:2: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  phone= soup.find_all(text=re.compile(r'Phone', re.I))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we will using regular expression to find Email which having \"@\" in text and display it\n",
        "email= re.findall(r'\\S+@\\S+', text)\n",
        "print(\"Email:\",email)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY7fpzqa02B8",
        "outputId": "0ecb3a4a-220e-444c-c5f9-88f5ce8c6218"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Email: ['office@iiitsurat.ac.in']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CODE BY UI22CS03\n",
        "#Note : The Phone no. and Email ID will only get extracted if the input url having that on webpage so further\n",
        "#I will more features like it can even natigate to another webpages of website so it can find more informations of a website"
      ],
      "metadata": {
        "id": "8jqrW-K16FbZ"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}